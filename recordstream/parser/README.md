# Recordstream Parser
This repository contains all scripts and pipeline configurations to ingest Hedera data. These services essentially function as a private mirror node that exposes data on the Hedera ledger. Additionally, there are services in this repository that collect data from additional sources, including third-party APIs and synthetic data generated by the Metrika Pinger

## Hedera Ledger Ingestion Services
There is a downloader that downloads files from a node's google bucket and dumps them in a local directory. Then a parser (orchestrator.py) picks up the downloaded files, decodes them, parses the data, and writes them to a file. 

- Records Downloader: `hedera/records/downloader.py`
- Records Orchestrator: `hedera/records/orchestrator.py`

## Data Models
Contains data models for the Hedera ledger and third party APIs

## Local Environment
To run the Hedera repository locally, you can do the following
1. Clone Hedera repo
2. Update the .env.sample file to work with your local environment - you can ask the Hedera team for any connection/credentials with external datasources
3. Make sure you're on python 3.9.x `python3 --version`
4. Make sure you're on poetry 1.2.x `poetry -v`
5. Install packages with poetry `poetry install`
6. You can use the below commands to run the Hedera services
- Records Downloader: `poetry run record-file-downloader`
- Records Orchestrator: `poetry run record-file-orchestrator`

## Backfilling Missing Data
In the case that there was a bug in a parser or any downtime, we may need to backfill data we missed during an outage. All of the Hedera ledger ingestion services have a "backfill" mode that can be used to do so. Below is a guide on how to do so (please note backfilling will likely need to be done in dedicated VM that is connected to Elasticsearch; the SRE team can help set this up if needed)
1. Download the files from the timeframe where no (or erroneous) data was collected
- `poetry run python hedera/cli.py record-file-downloader --backfill-marker "<pattern>"`
- The `<downloader>` parameter can be any of the downloaders listed above in the Local Environment section
- The `marker` parameter reflects the location/filenames (time-based) to collect from the google bucket. Hedera's files use the following format `YYYY-MM-DDTHH_mm_ss`
- Make sure the downloader is trying to get data from an online node, otherwise the marker will be reset
2. Parse the files from the timeframe where no (or erroneous) data was collected
- `poetry run python hedera/cli.py record-file-orchestrator --backfill-marker "<pattern>"`
- The `<orchestrator>` parameter can be any of the orchestrators listed above in the Local Environment section
- The `marker` parameter reflects the local location the files have been downloaded to. Please use the following format `YYYY-MM-DD`
3. Validate data has been shipped to Elasticsearch
4. Backfill any rollups/alerts/synthetics that are required
